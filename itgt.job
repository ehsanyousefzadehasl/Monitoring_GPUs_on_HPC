#!/bin/bash

#SBATCH --job-name=cuda_test_job_name      # Job name
#SBATCH --output=cuda_test_output_name     # output file name
#SBATCH --cpus-per-task=2                  # Schedule 2 cores (includes hyperthreading)
#SBATCH --gres=gpu                         # Schedule a GPU, it can be on 2 gpus like gpu:2
#SBATCH --time=00:05:00                    # Run time (hh:mm:ss)
#SBATCH --partition=scavenge               # Run on any permitted queue that has availability
#SBATCH --exclusive			   # Exclusive access to the server

# load cuda module
module load CUDA/12.1.1

# compile the cuda code
nvcc test_cuda.cu -o test_cuda

# start the monitoring tools in parallel to the program (that is why you need the &)

top -i -b > top-log.txt &

dcgmi dmon -e 155,156,200,201,203,204,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012 > dcgmi-log.out &

nvidia-smi --query-gpu=gpu_name,pstate,timestamp,utilization.gpu,utilization.memory,memory.total,memory.used --format=csv -l 1 -f nvidia-smi-log.out &

# run the program
./test_cuda
